{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d6fmq0-k88_5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul9UhZjbRFux"
      },
      "source": [
        "#**Product: Amazon Alexa**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Assignment Natural Language processsing - Sentiment Analysis**\n",
        "\n",
        "### **Customer Review Classification using Random Forest**\n",
        "\n",
        "- Dataset consists of 3000 Amazon customer reviews, star ratings, date of review, variant and feedback of various amazon Alexa products like Alexa Echo, Echo dots.\n",
        "- **The objective is to discover insights into consumer reviews and perfrom sentiment analysis on the data.** Positive or Negative review?\n",
        "- Dataset: www.kaggle.com/sid321axn/amazon-alexa-reviews also provided(`amazon_alexa.tsv`)\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### **Follow the instructions and complete each TODO to complete the assessment on the essential steps in building and evaluating a classification model.**\n",
        "\n",
        "\n",
        "\n",
        "**Dataset Information:**\n",
        "\n",
        "The dataset consists of customer reviews for Amazon Alexa products, including various features related to the product variation, customer rating, and feedback sentiment.\n",
        "\n",
        "_Features/Columns_:\n",
        "* rating: The customer rating of the product (scale of 1 to 5).\n",
        "* date: The date when the review was posted.\n",
        "* variation: The variation or type of Alexa product the review is for (e.g., \"Charcoal Fabric\", \"Walnut Finish\").\n",
        "* verified_reviews: The actual review text written by the customer.\n",
        "* feedback: The target variable indicating the sentiment of the review (1 for positive sentiment and 0 for negative sentiment).\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LrF9zCCtwBgS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAIQaVKb6MSV"
      },
      "outputs": [],
      "source": [
        "# Amazon Alexa Customer Review Sentiment Analysis\n",
        "# Objective: Classify reviews as positive or negative using Random Forest\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# TODO: Import necessary libraries\n",
        "# Hint: You'll need pandas, numpy, matplotlib, seaborn, and various sklearn modules\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# TODO: Load the dataset\n",
        "# Hint: Use pandas to read the CSV file from your Google Drive\n",
        "\n",
        "# Data Visualization and Clean Up\n",
        "# TODO: Visualize the distribution of feedback\n",
        "# Hint: Use seaborn's countplot function\n",
        "\n",
        "# TODO: Visualize the relationship between variations and ratings\n",
        "# Hint: Use seaborn's barplot function\n",
        "\n",
        "# TODO: Drop irrelevant columns\n",
        "# Hint: Use the drop() method to remove 'date' and 'rating' columns\n",
        "\n",
        "# One-Hot Encoding\n",
        "# TODO: Perform one-hot encoding on the 'variation' column\n",
        "# Hint: Use pandas get_dummies() function\n",
        "\n",
        "# Tokenization (Count Vectorizer)\n",
        "# TODO: Tokenize the 'verified_reviews' column\n",
        "# Hint: Use CountVectorizer from sklearn.feature_extraction.text\n",
        "\n",
        "# TODO: Combine tokenized reviews with the main dataframe\n",
        "# Hint: Use pd.concat() to join the dataframes\n",
        "\n",
        "# Prepare data for modeling\n",
        "# TODO: Split the data into features (X) and target (y)\n",
        "# Hint: The target variable is 'feedback'\n",
        "\n",
        "# TODO: Split the data into training and testing sets\n",
        "# Hint: Use train_test_split from sklearn.model_selection\n",
        "\n",
        "# Train the Random Forest model\n",
        "# TODO: Create and train the Random Forest model\n",
        "# Hint: Use RandomForestClassifier from sklearn.ensemble\n",
        "\n",
        "# Evaluate the model\n",
        "# TODO: Generate predictions and create confusion matrix\n",
        "# Hint: Use the predict() method and confusion_matrix from sklearn.metrics\n",
        "\n",
        "# TODO: Plot confusion matrix\n",
        "# Hint: Use seaborn's heatmap function\n",
        "\n",
        "# TODO: Print classification report\n",
        "# Hint: Use classification_report from sklearn.metrics\n",
        "\n",
        "# Feature Importance\n",
        "# TODO: Visualize feature importance\n",
        "# Hint: Access feature_importances_ attribute of the trained model\n",
        "\n",
        "# TODO: Make predictions on new data\n",
        "# Hint: Create a function that takes a new review text, preprocesses it,\n",
        "# and uses the trained model to predict its sentiment\n",
        "\n",
        "# Example usage of your prediction function:\n",
        "# new_review = \"I love my Alexa device! It's so helpful.\"\n",
        "# predicted_sentiment = predict_sentiment(new_review)\n",
        "# print(f\"The sentiment of the new review is: {predicted_sentiment}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 1: Import Libraries and Dataset\n",
        "\n",
        "# Hint: You need to import libraries like pandas, numpy, matplotlib, seaborn, etc.\n",
        "# Don't forget to mount Google Drive and load the CSV file using pandas.\n",
        "# Use `pd.read_csv()` to load the data into a pandas DataFrame.\n",
        "\n",
        "# TODO: Import necessary libraries\n",
        "\n",
        "# TODO: Mount Google Drive\n",
        "\n",
        "# TODO: Load the dataset into a DataFrame and preview the first few rows.\n",
        "\n",
        "\n",
        "# Hint: Use `sns.countplot()` to visualize the feedback distribution and a bar plot to compare variations and feedback.\n",
        "# Drop the columns 'date' and 'rating' as they are not relevant for the analysis.\n",
        "\n",
        "# TODO: Visualize the distribution of feedback (positive/negative)\n",
        "\n",
        "# TODO: Visualize the relationship between product variation and feedback\n",
        "\n",
        "# TODO: Drop irrelevant columns ('date', 'rating')\n",
        "\n",
        "\n",
        "\n",
        "# Hint: Use `pd.get_dummies()` to create one-hot encoded columns for 'variation'.\n",
        "# Then, concatenate these encoded columns back to the original DataFrame and drop the 'variation' column.\n",
        "\n",
        "# TODO: Perform one-hot encoding on the 'variation' column\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Hint: Use `CountVectorizer` to tokenize the text data and convert it into numerical representation.\n",
        "# After transforming the text, drop the 'verified_reviews' column and concatenate the numerical data with the rest of the DataFrame.\n",
        "\n",
        "# TODO: Tokenize the 'verified_reviews' column using CountVectorizer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Hint: Use `train_test_split()` to split the data into training and testing sets.\n",
        "# You need to specify `test_size=0.2` to reserve 20% of the data for testing.\n",
        "\n",
        "# TODO: Split the data into training and testing sets\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Hint: Initialize a `RandomForestClassifier` with 100 estimators.\n",
        "# Use the `fit()` method to train the model on the training data.\n",
        "\n",
        "# TODO: Define and train a Random Forest Classifier\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Hint: Use the `predict()` method to generate predictions for the test data.\n",
        "# Use `confusion_matrix()` to create the confusion matrix and visualize it using a heatmap.\n",
        "# Print out a `classification_report()` to evaluate the model's precision, recall, and F1 score.\n",
        "\n",
        "# TODO: Generate predictions and evaluate the model's performance using a confusion matrix and classification report\n",
        "\n",
        "\n",
        "\n",
        "# Task 8: Analyze Model Performance\n",
        "# Hint: Use the `score()` method to calculate accuracy for both training and test sets.\n",
        "# Compare the results and discuss if the model is overfitting or underfitting.\n",
        "\n",
        "# TODO: Compare training and testing accuracy and discuss model performance\n"
      ],
      "metadata": {
        "id": "o5slozJ77OuR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}